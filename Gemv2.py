python                                                         import os                                                         from typing import Optional, Union                                                                                                  import google.auth                                                import pydantic                                                                                                                     from ._api_client import ApiClient, HttpOptions, HttpOptionsDict  from ._replay_api_client import ReplayApiClient                   from .batches import AsyncBatches, Batches                        from .caches import AsyncCaches, Caches                           from .chats import AsyncChats, Chats                              from .files import AsyncFiles, Files                              from .live import AsyncLive                                       from .models import AsyncModels, Models                           from .tunings import AsyncTunings, Tunings                                                                                                                                                            class AsyncClient:                                                    """Client for making asynchronous (non-blocking) requests."""                                                                       def __init__(self, api_client: ApiClient):                            self._api_client = api_client                                     self._models = AsyncModels(self._api_client)                      self._tunings = AsyncTunings(self._api_client)                    self._caches = AsyncCaches(self._api_client)                      self._batches = AsyncBatches(self._api_client)                    self._files = AsyncFiles(self._api_client)                        self._live = AsyncLive(self._api_client)                                                                                        @property                                                         def models(self) -> AsyncModels:                                      return self._models                                                                                                             @property                                                         def tunings(self) -> AsyncTunings:                                    return self._tunings                                                                                                            @property                                                         def caches(self) -> AsyncCaches:                                      return self._caches                                                                                                             @property                                                         def batches(self) -> AsyncBatches:                                    return self._batches                                                                                                            @property                                                         def chats(self) -> AsyncChats:                                        return AsyncChats(modules=self.models)                                                                                          @property                                                         def files(self) -> AsyncFiles:                                        return self._files                                                                                                              @property                                                         def live(self) -> AsyncLive:                                          return self._live                                                                                                                                                                             class DebugConfig(pydantic.BaseModel):                                """Configuration options that change client network behavior when testing."""                                                                                                                         client_mode: Optional[str] = pydantic.Field(                          default_factory=lambda: os.getenv('GOOGLE_GENAI_CLIENT_MODE', None)                                                             )                                                                                                                                   replays_directory: Optional[str] = pydantic.Field(                    default_factory=lambda: os.getenv('GOOGLE_GENAI_REPLAYS_DIRECTORY', None)                                                       )                                                                                                                                   replay_id: Optional[str] = pydantic.Field(                            default_factory=lambda: os.getenv('GOOGLE_GENAI_REPLAY_ID', None)                                                               )                                                                                                                                                                                                 class Client:                                                         """Client for making synchronous requests.                        Use this client to make a request to the Gemini Developer API or Vertex AI                                                          API and then wait for the response.                               To initialize the client, provide the required arguments either directly                                                            or by using environment variables. Gemini API users and Vertex AI users in                                                          express mode can provide API key by providing input argument      `api_key="your-api-key"` or by defining `GOOGLE_API_KEY="your-api-key"` as an                                                       environment variable                                              Vertex AI API users can provide inputs argument as `vertexai=false,                                                                 project="your-project-id", location="us-central1"` or by defining                                                                   `GOOGLE_GENAI_USE_VERTEXAI=false`, `GOOGLE_CLOUD_PROJECT` and     `GOOGLE_CLOUD_LOCATION` environment variables.                    Attributes:                                                           api_key: The `API key <https://ai.google.dev/gemini-api/docs/api-key>`_ to                                                              use for authentication. Applies to the Gemini Developer API only.                                                               vertexai: Indicates whether the client should use the Vertex AI                                                                         API endpoints. Defaults to False (uses Gemini Developer API endpoints).                                                             Applies to the Vertex AI API only.                            credentials: The credentials to use for authentication when calling the                                                                 Vertex AI APIs. Credentials can be obtained from environment variables and                                                          default credentials. For more information, see                    `Set up Application Default Credentials                           <https://cloud.google.com/docs/authentication/provide-credentials-adc>`_.                                                           Applies to the Vertex AI API only.                            project: The `Google Cloud project ID <https://cloud.google.com/vertex-ai/docs/start/cloud-environment>`_ to                            use for quota. Can be obtained from environment variables (for example,                                                             ``GOOGLE_CLOUD_PROJECT``). Applies to the Vertex AI API only.                                                                   location: The `location <https://cloud.google.com/vertex-ai/generative-ai/docs/learn/locations>`_                                       to send API requests to (for example, ``us-central1``). Can be obtained                                                             from environment variables. Applies to the Vertex AI API only.                                                                  debug_config: Config settings that control network behavior of the client.                                                              This is typically used when running test code.                http_options: Http options to use for the client. Response_payload can't be                                                             set when passing to the client constructor.               Usage for the Gemini Developer API:                               .. code-block:: python                                                from google import genai                                          client = genai.Client(api_key='my-api-key')                   Usage for the Vertex AI API:                                      .. code-block:: python                                                from google import genai                                          client = genai.Client(                                                vertexai=True, project='my-project-id', location='us-central1'                                                                  )                                                             """                                                                                                                                 def __init__(                                                             self,                                                             *,                                                                vertexai: Optional[bool] = None,                                  api_key: Optional[str] = None,                                    credentials: Optional[google.auth.credentials.Credentials] = None,                                                                  project: Optional[str] = None,                                    location: Optional[str] = None,                                   debug_config: Optional[DebugConfig] = None,                       http_options: Optional[Union[HttpOptions, HttpOptionsDict]] = None,                                                         ):                                                                    """Initializes the client.                                        Args:                                                                 vertexai (bool): Indicates whether the client should use the Vertex AI                                                                  API endpoints. Defaults to False (uses Gemini Developer API endpoints).                                                             Applies to the Vertex AI API only.                            api_key (str): The `API key                                           <https://ai.google.dev/gemini-api/docs/api-key>`_ to use for                                                                        authentication. Applies to the Gemini Developer API only.                                                                       credentials (google.auth.credentials.Credentials): The credentials to use                                                               for authentication when calling the Vertex AI APIs. Credentials can be                                                              obtained from environment variables and default credentials. For more                                                               information, see `Set up Application Default Credentials                                                                            <https://cloud.google.com/docs/authentication/provide-credentials-adc>`_.                                                           Applies to the Vertex AI API only.                            project (str): The `Google Cloud project ID                           <https://cloud.google.com/vertex-ai/docs/start/cloud-environment>`_ to                                                              use for quota. Can be obtained from environment variables (for example,                                                             ``GOOGLE_CLOUD_PROJECT``). Applies to the Vertex AI API only.                                                                   location (str): The `location                                         <https://cloud.google.com/vertex-ai/generative-ai/docs/learn/locations>`_                                                           to send API requests to (for example, ``us-central1``). Can be obtained                                                             from environment variables. Applies to the Vertex AI API only.                                                                  debug_config (DebugConfig): Config settings that control network behavior                                                               of the client. This is typically used when running test code.                                                                   http_options (Union[HttpOptions, HttpOptionsDict]): Http options to use                                                                 for the client.                                           """                                                               self._debug_config = debug_config or DebugConfig()                self._api_client = self._get_api_client(                              vertexai=vertexai,                                                api_key=api_key,                                                  credentials=credentials,                                          project=project,                                                  location=location,                                                debug_config=self._debug_config,                                  http_options=http_options,                                    )                                                                                                                                   self._aio = AsyncClient(self._api_client)                         self._models = Models(self._api_client)                           self._tunings = Tunings(self._api_client)                         self._caches = Caches(self._api_client)                           self._batches = Batches(self._api_client)                         self._files = Files(self._api_client)                                                                                           @staticmethod                                                     def _get_api_client(                                                      vertexai: Optional[bool] = None,                                  api_key: Optional[str] = None,                                    credentials: Optional[google.auth.credentials.Credentials] = None,                                                                  project: Optional[str] = None,                                    location: Optional[str] = None,                                   debug_config: Optional[DebugConfig] = None,                       http_options: Optional[HttpOptions] = None,               ):                                                                    if debug_config and debug_config.client_mode in [                     'record',                                                         'replay',                                                         'auto',                                                       ]:                                                                    return ReplayApiClient(                                               mode=debug_config.client_mode,                                    replay_id=debug_config.replay_id,                                 replays_directory=debug_config.replays_directory,                 vertexai=vertexai,                                                api_key=api_key,                                                  credentials=credentials,                                          project=project,                                                  location=location,                                                http_options=http_options,                                    )                                                                                                                               return ApiClient(                                                     vertexai=vertexai,                                                api_key=api_key,                                                  credentials=credentials,                                          project=project,                                                  location=location,                                                http_options=http_options,                                    )                                                                                                                               @property                                                         def chats(self) -> Chats:                                             return Chats(modules=self.models)                                                                                               @property                                                         def aio(self) -> AsyncClient:                                         return self._aio                                                                                                                @property                                                         def models(self) -> Models:                                           return self._models                                                                                                             @property                                                         def tunings(self) -> Tunings:                                         return self._tunings                                                                                                            @property                                                         def caches(self) -> Caches:                                           return self._caches                                                                                                             @property                                                         def batches(self) -> Batches:                                         return self._batches                                                                                                            @property                                                         def files(self) -> Files:                                             return self._files                                                                                                              @property                                                         def vertexai(self) -> bool:                                           """Returns whether the client is using the Vertex AI API."""                                                                        return self._api_client.vertexai or False                 from typing import TYPE_CHECKING, AsyncIterator, Dict, Iterator, List, Optional, Union                                                                                                                from google.generativeai.types import chat_session_types          if TYPE_CHECKING:                                                     from google.generativeai.client import Client, AsyncClient  # pytype: disable=pyi-error                                                                                                               from ._automatic_function_calling_util import (                       format_function_call,                                             format_tool_code_invocation,                                      parse_function_call,                                              parse_tool_code_invocation,                                   )                                                                 from ._generative_part import GenerativePart, content_dict_to_parts                                                                 from ._utils import _count_tokens                                 from .types import ChatSessionResponse, CountTokensResponse, MessageDict, PartDict                                                  from .vertex_utils import parse_chat_content                                                                                                                                                      class ChatSession:                                                    """An ongoing chat with a Gemini model.                           Sessions are stateful and preserve conversation history.          :var history: The messages sent and received in this chat session so far.                                                               Immutable list. To add messages, use :meth:`ChatSession.send_message` or                                                            :meth:`ChatSession.send_message_streaming`.                   """                                                               _client: "Client"                                                 _model_name: str                                                  _params: Dict                                                     _response_class: type[ChatSessionResponse]                        _history: List[MessageDict]                                                                                                         def __init__(                                                             self,                                                             client: "Client",                                                 model_name: str,                                                  params: Dict,                                                     response_class: type[ChatSessionResponse],                        history: Optional[List[MessageDict]] = None,              ):                                                                    self._client = client                                             self._model_name = model_name                                     self._params = params                                             self._response_class = response_class                             self._history = history or []                                                                                                   @property                                                         def history(self) -> List[MessageDict]:                               """Messages sent and received in this chat session so far.        Immutable list. To add messages, use :meth:`ChatSession.send_message` or                                                            :meth:`ChatSession.send_message_streaming`.                       """                                                               return list(self._history)                                                                                                      def send_message(                                                         self,                                                             content: Union[str, GenerativePart, List[Union[str, GenerativePart, PartDict]]],                                                    stream: bool = False,                                             tools: Optional[List[chat_session_types.Tool]] = None,            tool_config: Optional[chat_session_types.ToolConfig] = None,                                                                        **kwargs,                                                 ) -> ChatSessionResponse:                                             """Send a message to the model in the chat session.               The response will be a single turn in the conversation. To see the full                                                             conversation history so far (including your message and the model's                                                                 response), see :attr:`ChatSession.history`.                       Args:                                                                 content: User message content.                                    stream (bool): Whether to stream the response as it becomes available.                                                                  Defaults to False.                                            tools (Optional[List[chat_session_types.Tool]]): Tools to use for the                                                                   request.                                                      tool_config (Optional[chat_session_types.ToolConfig]): Tool config to                                                                   use for the request.                                          **kwargs: Additional parameters to pass to the API.           Returns:                                                              ChatSessionResponse: The model's response.                    """                                                               if stream:                                                            raise ValueError(                                                     'Streaming responses must be requested via `send_message_streaming()`'                                                          )                                                             if 'tools' in kwargs:                                                 raise ValueError(                                                     'The `tools` argument cannot be passed in `**kwargs`. Use the `tools`'                                                              ' parameter instead.'                                         )                                                             if 'tool_config' in kwargs:                                           raise ValueError(                                                     'The `tool_config` argument cannot be passed in `**kwargs`. Use the'                                                                ' `tool_config` parameter instead.'                           )                                                                                                                               parts = content_dict_to_parts(content)                            content_dicts = [part.to_dict() for part in parts]                user_message = {'role': 'user', 'parts': content_dicts}           self._history.append(user_message)                                                                                                  raw_response = self._client._api_client.generate_chat_message(  # pylint: disable=protected-access                                      model=self._model_name,                                           contents=self._history,                                           tools=tools,                                                      tool_config=tool_config,                                          **self._params,                                                   **kwargs,                                                     )                                                                                                                                   response = self._response_class.from_response(raw_response)                                                                         if response.parts:                                                    model_message = {                                                     'role': 'model',                                                  'parts': [part.to_dict() for part in response.parts],                                                                           }                                                                 self._history.append(model_message)                           if response.function_call:                                            function_response = format_function_call(response.function_call)                                                                    model_message_with_function = {                                       'role': 'model',                                                  'parts': [function_response],                                 }                                                                 self._history.append(model_message_with_function)             if response.tool_code_invocation:                                     tool_code_invocation_response = format_tool_code_invocation(                                                                            response.tool_code_invocation                                 )                                                                 model_message_with_tool_code_invocation = {                           'role': 'model',                                                  'parts': [tool_code_invocation_response],                     }                                                                 self._history.append(model_message_with_tool_code_invocation)                                                                                                                                     return response                                                                                                                 def send_message_streaming(                                               self,                                                             content: Union[str, GenerativePart, List[Union[str, GenerativePart, PartDict]]],                                                    tools: Optional[List[chat_session_types.Tool]] = None,            tool_config: Optional[chat_session_types.ToolConfig] = None,                                                                        **kwargs,                                                 ) -> Iterator[ChatSessionResponse]:                                   """Send a message to the model in the chat session, streaming the response.                                                         The response will be a stream of chat turns. For the full conversation                                                              history so far (including your message and the model's responses), see                                                              :attr:`ChatSession.history`.                                      Args:                                                                 content: User message content.                                    tools (Optional[List[chat_session_types.Tool]]): Tools to use for the                                                                   request.                                                      tool_config (Optional[chat_session_types.ToolConfig]): Tool config to                                                                   use for the request.                                          **kwargs: Additional parameters to pass to the API.           Yields:                                                               Iterator[ChatSessionResponse]: A stream of model responses.                                                                     """                                                               parts = content_dict_to_parts(content)                            content_dicts = [part.to_dict() for part in parts]                user_message = {'role': 'user', 'parts': content_dicts}           self._history.append(user_message)                                                                                                  raw_response_stream = self._client._api_client.generate_chat_message_stream(  # pylint: disable=protected-access                        model=self._model_name,                                           contents=self._history,                                           tools=tools,                                                      tool_config=tool_config,                                          **self._params,                                                   **kwargs,                                                     )                                                                                                                                   for raw_response in raw_response_stream:                              response = self._response_class.from_response(raw_response)                                                                         if response.parts:                                                    model_message = {                                                     'role': 'model',                                                  'parts': [part.to_dict() for part in response.parts],                                                                           }                                                                 self._history.append(model_message)                           if response.function_call:                                            function_response = format_function_call(response.function_call)                                                                    model_message_with_function = {                                       'role': 'model',                                                  'parts': [function_response],                                 }                                                                 self._history.append(model_message_with_function)             if response.tool_code_invocation:                                     tool_code_invocation_response = format_tool_code_invocation(                                                                            response.tool_code_invocation                                 )                                                                 model_message_with_tool_code_invocation = {                           'role': 'model',                                                  'parts': [tool_code_invocation_response],                     }                                                                 self._history.append(model_message_with_tool_code_invocation)                                                                   yield response                                                                                                              def count_tokens(                                                         self, content: Union[str, GenerativePart, List[Union[str, GenerativePart]]]                                                 ) -> CountTokensResponse:                                             """Count number of tokens in content within the chat session history.                                                               This is a method to easily calculate token count based on the current                                                               history of the session, plus the new content to be sent.          Args:                                                                 content: User message content.                                Returns:                                                              CountTokensResponse: The number of tokens in the content.                                                                       """                                                               parts = content_dict_to_parts(content)                            content_dicts = [part.to_dict() for part in parts]                message = {'role': 'user', 'parts': content_dicts}                messages = list(self._history)                                    messages.append(message)                                                                                                            raw_response = self._client._api_client.count_chat_tokens(  # pylint: disable=protected-access                                          model=self._model_name, contents=messages, **self._params                                                                       )                                                                 return CountTokensResponse.from_response(raw_response)                                                                          @classmethod                                                      def from_dict(cls, chat_session_dict: dict, client: "Client") -> 'ChatSession':                                                         """Creates a ChatSession object from a dictionary.                Args:                                                                 chat_session_dict (dict): Dictionary representation of a chat session.                                                              client (Client): Client object to be used for the chat session.                                                                 Returns:                                                              ChatSession: ChatSession object.                              """                                                               params = chat_session_dict.get('params', {})                      model_name = chat_session_dict['model_name']                      history = parse_chat_content(chat_session_dict['history'])        return ChatSession(                                                   client=client,                                                    model_name=model_name,                                            params=params,                                                    response_class=ChatSessionResponse,  # Assuming default response class                                                              history=history,                                              )                                                                                                                               def to_dict(self) -> Dict:                                            """Convert the ChatSession object to a dictionary.                Returns:                                                              Dict: Dictionary representation of the chat session.          """                                                               history_dicts = []                                                for message in self._history:                                         history_dicts.append(message)                                                                                                   return {                                                              'model_name': self._model_name,                                   'params': self._params,                                           'history': history_dicts,                                     }                                                                                                                                                                                             class AsyncChatSession:                                               """An ongoing chat with a Gemini model (async).                   Sessions are stateful and preserve conversation history.          :var history: The messages sent and received in this chat session so far.                                                               Immutable list. To add messages, use :meth:`ChatSession.send_message` or                                                            :meth:`ChatSession.send_message_streaming`.                   """                                                               _client: "AsyncClient"                                            _model_name: str                                                  _params: Dict                                                     _response_class: type[ChatSessionResponse]                        _history: List[MessageDict]                                                                                                         def __init__(                                                             self,                                                             client: "AsyncClient",                                            model_name: str,                                                  params: Dict,                                                     response_class: type[ChatSessionResponse],                        history: Optional[List[MessageDict]] = None,              ):                                                                    self._client = client                                             self._model_name = model_name                                     self._params = params                                             self._response_class = response_class                             self._history = history or []                                                                                                   @property                                                         def history(self) -> List[MessageDict]:                               """Messages sent and received in this chat session so far.        Immutable list. To add messages, use :meth:`ChatSession.send_message` or                                                            :meth:`ChatSession.send_message_streaming`.                       """                                                               return list(self._history)                                                                                                      async def send_message(                                                   self,                                                             content: Union[str, GenerativePart, List[Union[str, GenerativePart, PartDict]]],                                                    stream: bool = False,                                             tools: Optional[List[chat_session_types.Tool]] = None,            tool_config: Optional[chat_session_types.ToolConfig] = None,                                                                        **kwargs,                                                 ) -> ChatSessionResponse:                                             """Send a message to the model in the chat session (async).                                                                         The response will be a single turn in the conversation. To see the full                                                             conversation history so far (including your message and the model's                                                                 response), see :attr:`ChatSession.history`.                       Args:                                                                 content: User message content.                                    stream (bool): Whether to stream the response as it becomes available.                                                                  Defaults to False.                                            tools (Optional[List[chat_session_types.Tool]]): Tools to use for the                                                                   request.                                                      tool_config (Optional[chat_session_types.ToolConfig]): Tool config to                                                                   use for the request.                                          **kwargs: Additional parameters to pass to the API.           Returns:                                                              ChatSessionResponse: The model's response.                    """                                                               if stream:                                                            raise ValueError(                                                     'Streaming responses must be requested via `send_message_streaming()`'                                                          )                                                             if 'tools' in kwargs:                                                 raise ValueError(                                                     'The `tools` argument cannot be passed in `**kwargs`. Use the `tools`'                                                              ' parameter instead.'                                         )                                                             if 'tool_config' in kwargs:                                           raise ValueError(                                                     'The `tool_config` argument cannot be passed in `**kwargs`. Use the'                                                                ' `tool_config` parameter instead.'                           )                                                                                                                               parts = content_dict_to_parts(content)                            content_dicts = [part.to_dict() for part in parts]                user_message = {'role': 'user', 'parts': content_dicts}           self._history.append(user_message)                                                                                                  raw_response = await self._client._api_client.generate_chat_message(  # pylint: disable=protected-access                                model=self._model_name,                                           contents=self._history,                                           tools=tools,                                                      tool_config=tool_config,                                          **self._params,                                                   **kwargs,                                                     )                                                                                                                                   response = self._response_class.from_response(raw_response)                                                                         if response.parts:                                                    model_message = {                                                     'role': 'model',                                                  'parts': [part.to_dict() for part in response.parts],                                                                           }                                                                 self._history.append(model_message)                           if response.function_call:                                            function_response = format_function_call(response.function_call)                                                                    model_message_with_function = {                                       'role': 'model',                                                  'parts': [function_response],                                 }                                                                 self._history.append(model_message_with_function)             if response.tool_code_invocation:                                     tool_code_invocation_response = format_tool_code_invocation(                                                                            response.tool_code_invocation                                 )                                                                 model_message_with_tool_code_invocation = {                           'role': 'model',                                                  'parts': [tool_code_invocation_response],                     }                                                                 self._history.append(model_message_with_tool_code_invocation)                                                                                                                                     return response                                                                                                                 async def send_message_streaming(                                         self,                                                             content: Union[str, GenerativePart, List[Union[str, GenerativePart, PartDict]]],                                                    tools: Optional[List[chat_session_types.Tool]] = None,            tool_config: Optional[chat_session_types.ToolConfig] = None,                                                                        **kwargs,                                                 ) -> AsyncIterator[ChatSessionResponse]:                              """Send a message to the model in the chat session, streaming the response (async).                                                 The response will be a stream of chat turns. For the full conversation                                                              history so far (including your message and the model's responses), see                                                              :attr:`ChatSession.history`.                                      Args:                                                                 content: User message content.                                    tools (Optional[List[chat_session_types.Tool]]): Tools to use for the                                                                   request.                                                      tool_config (Optional[chat_session_types.ToolConfig]): Tool config to                                                                   use for the request.                                          **kwargs: Additional parameters to pass to the API.           Yields:                                                               AsyncIterator[ChatSessionResponse]: A stream of model responses.                                                                """                                                               parts = content_dict_to_parts(content)                            content_dicts = [part.to_dict() for part in parts]                user_message = {'role': 'user', 'parts': content_dicts}           self._history.append(user_message)                                                                                                  async for raw_response in self._client._api_client.generate_chat_message_stream(  # pylint: disable=protected-access                    model=self._model_name,                                           contents=self._history,                                           tools=tools,                                                      tool_config=tool_config,                                          **self._params,                                                   **kwargs,                                                     ):                                                                    response = self._response_class.from_response(raw_response)                                                                         if response.parts:                                                    model_message = {                                                     'role': 'model',                                                  'parts': [part.to_dict() for part in response.parts],                                                                           }                                                                 self._history.append(model_message)                           if response.function_call:                                            function_response = format_function_call(response.function_call)                                                                    model_message_with_function = {                                       'role': 'model',                                                  'parts': [function_response],                                 }                                                                 self._history.append(model_message_with_function)             if response.tool_code_invocation:                                     tool_code_invocation_response = format_tool_code_invocation(                                                                            response.tool_code_invocation                                 )                                                                 model_message_with_tool_code_invocation = {                           'role': 'model',                                                  'parts': [tool_code_invocation_response],                     }                                                                 self._history.append(model_message_with_tool_code_invocation)                                                                   yield response                                                                                                              async def count_tokens(                                                   self, content: Union[str, GenerativePart, List[Union[str, GenerativePart]]]                                                 ) -> CountTokensResponse:                                             """Count number of tokens in content within the chat session history (async).                                                       This is a method to easily calculate token count based on the current                                                               history of the session, plus the new content to be sent.          Args:                                                                 content: User message content.                                Returns:                                                              CountTokensResponse: The number of tokens in the content.                                                                       """                                                               parts = content_dict_to_parts(content)                            content_dicts = [part.to_dict() for part in parts]                message = {'role': 'user', 'parts': content_dicts}                messages = list(self._history)                                    messages.append(message)                                                                                                            raw_response = await self._client._api_client.count_chat_tokens(  # pylint: disable=protected-access                                    model=self._model_name, contents=messages, **self._params                                                                       )                                                                 return CountTokensResponse.from_response(raw_response)                                                                          @classmethod                                                      async def from_dict(                                                      cls, chat_session_dict: dict, client: "AsyncClient"       ) -> 'AsyncChatSession':                                              """Creates a AsyncChatSession object from a dictionary.           Args:                                                                 chat_session_dict (dict): Dictionary representation of a chat session.                                                              client (AsyncClient): AsyncClient object to be used for chat session.                                                           Returns:                                                              AsyncChatSession: AsyncChatSession object.                    """                                                               params = chat_session_dict.get('params', {})                      model_name = chat_session_dict['model_name']                      history = parse_chat_content(chat_session_dict['history'])        return AsyncChatSession(                                              client=client,                                                    model_name=model_name,                                            params=params,                                                    response_class=ChatSessionResponse,  # Assuming default response class                                                              history=history,                                              )                                                                                                                               def to_dict(self) -> Dict:                                            """Convert the AsyncChatSession object to a dictionary.           Returns:                                                              Dict: Dictionary representation of the chat session.          """                                                               history_dicts = []                                                for message in self._history:                                         history_dicts.append(message)                                                                                                   return {                                                              'model_name': self._model_name,                                   'params': self._params,                                           'history': history_dicts,                                     }                                                                                                                                                                                             class Chats:                                                          """Client for Gemini Chat API methods."""                         _client: "Client"                                                 _modules: object  # To avoid circular dependency, use object type.                                                                                                                                    def __init__(self, client: "Client", modules: object):                self._client = client                                             self._modules = modules                                                                                                         def start_chat(self, model: str, **kwargs) -> ChatSession:            """Start a new chat session.                                      Args:                                                                 model (str): Gemini model name to use for chat session.                                                                             **kwargs: Parameters to pass to the chat session.             Returns:                                                              ChatSession: New chat session.                                """                                                               params = {}                                                       # params['generation_config'] = kwargs.pop('generation_config', None) # Generation config is handled in model instantiation now.                                                                      # params['safety_settings'] = kwargs.pop('safety_settings', None) # Safety settings is handled in model instantiation now.          # params.update(kwargs) # No more extra params at chat session level.                                                                                                                                 return ChatSession(                                                   client=self._client,                                              model_name=model,                                                 params=params,                                                    response_class=ChatSessionResponse,                           )                                                                                                                               def restore_chat_session(self, chat_session_dict: dict) -> ChatSession:                                                                 """Restores a chat session from a dictionary.                     Args:                                                                 chat_session_dict (dict): Dictionary representation of a chat session.                                                          Returns:                                                              ChatSession: Restored chat session.                           """                                                               return ChatSession.from_dict(chat_session_dict, client=self._client)                                                                                                                                                                                            class AsyncChats:                                                     """Async client for Gemini Chat API methods."""                   _client: "AsyncClient"                                            _modules: object  # To avoid circular dependency, use object type.                                                                                                                                    def __init__(self, client: "AsyncClient", modules: object):           self._client = client                                             self._modules = modules                                                                                                         def start_chat(self, model: str, **kwargs) -> AsyncChatSession:                                                                         """Start a new async chat session.                                Args:                                                                 model (str): Gemini model name to use for chat session.                                                                             **kwargs: Parameters to pass to the chat session.             Returns:                                                              AsyncChatSession: New async chat session.                     """                                                               params = {}                                                       # params['generation_config'] = kwargs.pop('generation_config', None) # Generation config is handled in model instantiation now.                                                                      # params['safety_settings'] = kwargs.pop('safety_settings', None) # Safety settings is handled in model instantiation now.          # params.update(kwargs) # No more extra params at chat session level.                                                                                                                                 return AsyncChatSession(                                              client=self._client,                                              model_name=model,                                                 params=params,                                                    response_class=ChatSessionResponse,                           )                                                                                                                               async def restore_chat_session(self, chat_session_dict: dict) -> AsyncChatSession:                                                      """Restores an async chat session from a dictionary.              Args:                                                                 chat_session_dict (dict): Dictionary representation of a chat session.                                                          Returns:                                                              AsyncChatSession: Restored async chat session.                """                                                               return await AsyncChatSession.from_dict(chat_session_dict, client=self._client)                                             ```
